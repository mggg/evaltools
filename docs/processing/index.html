<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>evaltools.processing API documentation</title>
<meta name="description" content="Facilities for processing districting plans in a standardized, functional-programmy
way." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>evaltools.processing</code></h1>
</header>
<section id="section-intro">
<p>Facilities for processing districting plans in a standardized, functional-programmy
way.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Facilities for processing districting plans in a standardized, functional-programmy
way.
&#34;&#34;&#34;

from .fetch import submissions, tabularized, Submission
from .remap import remap
from .URLs import ids, one, csvs
from .AssignmentCompressor import AssignmentCompressor
from gerrychain.graph import Graph
from gerrychain.partition import Partition

__all__ = [
    &#34;submissions&#34;,
    &#34;tabularized&#34;,
    &#34;remap&#34;,
    &#34;ids&#34;,
    &#34;one&#34;,
    &#34;csvs&#34;,
    &#34;AssignmentCompressor&#34;,
    &#34;Submission&#34;
]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="evaltools.processing.URLs" href="URLs.html">evaltools.processing.URLs</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="evaltools.processing.fetch" href="fetch.html">evaltools.processing.fetch</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="evaltools.processing.csvs"><code class="name flex">
<span>def <span class="ident">csvs</span></span>(<span>state, ptype='plan')</span>
</code></dt>
<dd>
<div class="desc"><p>URL for accessing districtr plan metadata.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>state</code></strong></dt>
<dd><code>us.States</code> object (e.g. <code>us.states.WI</code>)</dd>
<dt><strong><code>ptype</code></strong></dt>
<dd>Type of plan we're retrieving; defaults to <code>"plan"</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>String with the appropriate URL.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def csvs(state, ptype=&#34;plan&#34;):
    &#34;&#34;&#34;
    URL for accessing districtr plan metadata.

    Args:
        state: `us.States` object (e.g. `us.states.WI`)
        ptype: Type of plan we&#39;re retrieving; defaults to `&#34;plan&#34;`.

    Returns:
        String with the appropriate URL.
    &#34;&#34;&#34;
    prefix = &#34;https://k61e3cz2ni.execute-api.us-east-2.amazonaws.com/prod/submissions/csv/&#34;
    suffix = f&#34;?type={ptype}&amp;length=10000&#34;
    return f&#34;{prefix}{state.name.lower()}{suffix}&#34;</code></pre>
</details>
</dd>
<dt id="evaltools.processing.ids"><code class="name flex">
<span>def <span class="ident">ids</span></span>(<span>state)</span>
</code></dt>
<dd>
<div class="desc"><p>URL for accessing districtr identifiers.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>state</code></strong></dt>
<dd>Name of the state (e.g. <code>"wisconsin"</code>) for which we're retrieving
districtr identifiers.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>String with the appropriate URL.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ids(state):
    &#34;&#34;&#34;
    URL for accessing districtr identifiers.

    Args:
        state: Name of the state (e.g. `&#34;wisconsin&#34;`) for which we&#39;re retrieving
            districtr identifiers.

    Returns:
        String with the appropriate URL.
    &#34;&#34;&#34;
    return f&#34;https://k61e3cz2ni.execute-api.us-east-2.amazonaws.com/prod/submissions/districtr-ids/{state.name.lower()}&#34;</code></pre>
</details>
</dd>
<dt id="evaltools.processing.one"><code class="name flex">
<span>def <span class="ident">one</span></span>(<span>identifier)</span>
</code></dt>
<dd>
<div class="desc"><p>URL for accessing an individual districtr plan.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>identifier</code></strong></dt>
<dd>distrivtr identifier.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>String with the appropriate URL.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def one(identifier):
    &#34;&#34;&#34;
    URL for accessing an individual districtr plan.

    Args:
        identifier: distrivtr identifier.

    Returns:
        String with the appropriate URL.
    &#34;&#34;&#34;
    return f&#34;https://districtr.org/.netlify/functions/planRead?id={identifier}&#34;</code></pre>
</details>
</dd>
<dt id="evaltools.processing.remap"><code class="name flex">
<span>def <span class="ident">remap</span></span>(<span>plans, unitmaps, popmap=None) ‑> Callable</span>
</code></dt>
<dd>
<div class="desc"><p>Re-maps assignments to the specified set of units.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>plans</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>The Pandas DataFrame produced by <code><a title="evaltools.processing.tabularized" href="#evaltools.processing.tabularized">tabularized()</a></code>.</dd>
<dt><strong><code>unitmaps</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dictionary whose keys are unit types appearing in the
<code>unitsType</code> column, and whose values are dictionaries mapping unique
identifiers of one set of geometries to unique identifiers (or lists
of unique identifiers) of another set of geometries; these correspond
to mappings generated by <code>unitmap()</code> and the inverse mapping generated
by <code>invert()</code>.</dd>
<dt><strong><code>popmap</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>A mapping from unit unique identifiers to
population values. Only applies when we are mapping from smaller
units to larger ones.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A function</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remap(plans, unitmaps, popmap=None) -&gt; Callable:
    &#34;&#34;&#34;
    Re-maps assignments to the specified set of units.

    Args:
        plans (DataFrame): The Pandas DataFrame produced by ``tabularized()``.
        unitmaps (dict): A dictionary whose keys are unit types appearing in the
            `unitsType` column, and whose values are dictionaries mapping unique
            identifiers of one set of geometries to unique identifiers (or lists
            of unique identifiers) of another set of geometries; these correspond
            to mappings generated by `unitmap()` and the inverse mapping generated
            by `invert()`.
        popmap (dict, optional): A mapping from unit unique identifiers to
            population values. Only applies when we are mapping from smaller
            units to larger ones.

    Returns:
        A function 
    &#34;&#34;&#34;
    def _(row):
        # Get the assignment for the row.
        assignment = ast.literal_eval(row[&#34;plan&#34;])

        # Attempt to get the type of units specified by the row; if we can&#39;t – i.e.
        # the user didn&#39;t specify a unit mapping corresponding to that unit type
        # in `unitmaps` – we leave the assignment alone and warn the user.
        try:
            unitsType = row[&#34;units&#34;]
            unitmap = unitmaps[unitsType]
        except:
            print(f&#34;No unit mapping provided for {row[&#39;units&#39;]}; skipping.&#34;)
            return assignment

        # What kind of mapping do we have? If `mapping` is from a single key
        # to a single value, then we&#39;re mapping units one-to-one (e.g. block IDs
        # to VTD IDs); otherwise, we&#39;re mapping units one-to-many (e.g. VTD IDs
        # to blocks). If `mapping` is of the former type, then it&#39;s possible that
        # some larger units may comprise smaller units in multiple districts. If
        # this is the case, then we assign larger units to the district in which
        # most of the larger unit&#39;s population resides; otherwise, we simply
        # assign all smaller units to whichever district the larger unit&#39;s in.
        firstvalue = next(iter(unitmap.values()))
        unitmapdirection = &#34;down&#34;

        # Mark which kind of mapping we have.
        if type(firstvalue) is list: unitmapdirection = &#34;down&#34;
        else: unitmapdirection = &#34;up&#34;

        # Now, based on the mapping type, return the appropriate mapping.
        if unitmapdirection == &#34;down&#34;: return _down(unitmap, assignment)
        return _up(unitmap, popmap, assignment)

    plans[&#34;plan&#34;] = plans.apply(_, axis=1)
    return plans</code></pre>
</details>
</dd>
<dt id="evaltools.processing.submissions"><code class="name flex">
<span>def <span class="ident">submissions</span></span>(<span>state, sample=None) ‑> List[<a title="evaltools.processing.fetch.Submission" href="fetch.html#evaltools.processing.fetch.Submission">Submission</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieves raw districtr objects; this includes both plan- and COI-based
submissions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>state</code></strong> :&ensp;<code>State</code></dt>
<dd><code>us.State</code> object (e.g. <code>us.states.WI</code>).</dd>
<dt><strong><code>sample</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of sample plans to retrieve.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A list of <code>Submissions</code>, either to be interpreted raw or tabularized.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def submissions(state, sample=None) -&gt; List[Submission]:
    &#34;&#34;&#34;
    Retrieves raw districtr objects; this includes both plan- and COI-based
    submissions.

    Args:
        state (State): `us.State` object (e.g. `us.states.WI`).
        sample (int, optional): The number of sample plans to retrieve.

    Returns:
        A list of `Submissions`, either to be interpreted raw or tabularized.
    &#34;&#34;&#34;
    # Get the appropriate URL and send the request. Made some basic ASCII art with
    # the second three variable names... it&#39;s like the request is loading letter
    # by letter.
    url = ids(state)
    __w = requests.get(url).text
    _aw = json.loads(__w)[&#34;ids&#34;]
    raw = _aw[:sample] if sample else _aw

    # Create `Submission` objects for each of the retrieved objects. Getting the
    # individual plans is the bottleneck here, and unfortunately we can&#39;t retrieve
    # them in bulk (... or can we?).
    submissions = []
    for entity in raw:
        # Retrieve the required data points.
        identifier = parse_id(entity[&#34;link&#34;], df=False)
        districtr = individual(identifier)
        
        # Force all plan keys and values to strings.
        plan = {
            str(k): str(v) if type(v) is not list else str(v[0])
            for k, v in districtr[&#34;plan&#34;][&#34;assignment&#34;].items()
        }
        units = districtr[&#34;plan&#34;][&#34;units&#34;][&#34;name&#34;]
        unitsType = districtr[&#34;plan&#34;][&#34;units&#34;][&#34;unitType&#34;]
        tileset = districtr[&#34;plan&#34;][&#34;units&#34;][&#34;tilesets&#34;][0][&#34;sourceLayer&#34;]

        # Create a new Submission.
        submissions.append(Submission(
            link=entity[&#34;link&#34;],
            id=identifier,
            plan=plan,
            units=units,
            unitsType=unitsType,
            tileset=tileset,
            type=entity[&#34;type&#34;]
        ))

    return submissions</code></pre>
</details>
</dd>
<dt id="evaltools.processing.tabularized"><code class="name flex">
<span>def <span class="ident">tabularized</span></span>(<span>state, submissions) ‑> Tuple[pandas.core.frame.DataFrame, pandas.core.frame.DataFrame, pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns districtr submission information in a tabular format.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>state</code></strong> :&ensp;<code>State</code></dt>
<dd><code>us.State</code> object (e.g. <code>us.states.WI</code>).</dd>
<dt><strong><code>submissions</code></strong> :&ensp;<code>list</code></dt>
<dd>List of <code><a title="evaltools.processing.Submission" href="#evaltools.processing.Submission">Submission</a></code> objects returned from a call to
<code><a title="evaltools.processing.submissions" href="#evaltools.processing.submissions">submissions()</a></code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Three dataframes corresponding to plan-based submissions, COI-based
submissions, and written submissions to the provided state.</p>
<h2 id="example">Example</h2>
<p>Prototypical example usage.</p>
<pre><code>import us
from evaltools.retrieve import submissions, tabularized

# Set the state.
state = us.states.WI

# Retrieve the raw districtr submissions, then tabularize them.
subs = submissions(state)
plans, cois, written = tabularized(state, subs)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tabularized(state, submissions) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    &#34;&#34;&#34;
    Returns districtr submission information in a tabular format.

    Args:
        state (State): `us.State` object (e.g. `us.states.WI`).
        submissions (list): List of `Submission` objects returned from a call to
            `submissions`.

    Returns:
        Three dataframes corresponding to plan-based submissions, COI-based
        submissions, and written submissions to the provided state.

    Example:
        Prototypical example usage.
        
            import us
            from evaltools.retrieve import submissions, tabularized

            # Set the state.
            state = us.states.WI

            # Retrieve the raw districtr submissions, then tabularize them.
            subs = submissions(state)
            plans, cois, written = tabularized(state, subs)

    &#34;&#34;&#34;
    # Sort submissions. (Not sure why this is necessary? Holdover from previous
    # fetching code.)
    submissions = list(sorted(submissions, key=lambda s: s.id))

    # Categorize into three categories: plan submissions, COI submissions, and
    # written submissions (which are ignored as they don&#39;t appear in the list
    # of submissions).
    _plans = [s.dict() for s in submissions if s.type == &#34;plan&#34;]
    _cois = [s.dict() for s in submissions if s.type == &#34;coi&#34;]
    
    # Create preliminary dataframes so we can do safe `merge`s rather than rely
    # explicitly on sorting; this also allows us to specify a sample size if
    # we&#39;re only looking to sample a specific number of plans.
    subset_plans = pd.DataFrame.from_records(_plans)
    subset_cois = pd.DataFrame.from_records(_cois)
    
    # Get appropriate URLs and create dataframes.
    plans_url = csvs(state)
    cois_url = csvs(state, ptype=&#34;coi&#34;)
    written_url = csvs(state, ptype=&#34;written&#34;)

    plans = as_dataframe(plans_url)
    cois = as_dataframe(cois_url)
    writtens = as_dataframe(written_url)

    # Adjust column contents for the plan and COI dataframes.
    for universe in [plans, cois]:
        # Adjust the `link` column type and create an `id` column from it.
        universe[&#34;link&#34;] = universe[&#34;link&#34;].astype(str)
        universe[&#34;id&#34;] = parse_id(universe[&#34;link&#34;])

    # Adjust column contents for all dataframes.
    for df in [plans, cois, writtens]: df[&#34;datetime&#34;] = parse_datetime(df[&#34;datetime&#34;])

    # Add the retrieved plan data to the dataframes *if the subset dataframes
    # contain items*.

    if not subset_plans.empty: plans = plans.merge(subset_plans, on=&#34;id&#34;)
    else: plans = pd.DataFrame()
    if not subset_cois.empty: cois = cois.merge(subset_cois, on=&#34;id&#34;)
    else: cois = pd.DataFrame()

    # Drop bad columns and rename. Not sure why we have to `inplace` things here,
    # but... fine.
    for df in [plans, cois]:
        if not df.empty:
            df.drop([&#34;type_x&#34;, &#34;link_x&#34;, &#34;coalition&#34;], axis=1, inplace=True)
            df.rename({&#34;type_y&#34;: &#34;type&#34;, &#34;link_y&#34;: &#34;link&#34;}, axis=1, inplace=True)

    return plans, cois, writtens</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="evaltools.processing.AssignmentCompressor"><code class="flex name class">
<span>class <span class="ident">AssignmentCompressor</span></span>
<span>(</span><span>identifiers, window=10, location='compressed.ac')</span>
</code></dt>
<dd>
<div class="desc"><p>A class for compressing and decompressing lots of assignments very, very
quickly. Intended for use with <code>jsonlines</code>-like libraries (where assignments
are read in line-by-line) or for network requests (where assignments are
retrieved one-by-one). When decompressing, yields <code>dict</code>s where keys are
in sorted order.</p>
<p>The compression schema considers the set of unique identifiers, imposes an
ordering (lexicographic order) on the identifiers, and matches the assignment
to that ordering. We assign all unassigned units to <code>"-1"</code> and, once the
default cache size is hit (or assignments are no longer being read in),
compress all assignments in the cache. Assignments are read in and out in
the same order, and the keys for each assignment are in the same order.</p>
<h2 id="example">Example</h2>
<p>To compress assignments, we need a set of unique identifiers such that
each identifier maps one geometric unit to one district.</p>
<pre><code>...

geoids = blocks["GEOID20"].astype(str)
ac = AssignmentCompressor(geoids, location="compressed-assignments.ac")

with ac as compressor:
    for assignment in assignments:
        # Here, ensure that all assignments have string keys and
        # string values; also ensure that an assignment's keys are
        # a subset of geoids (or whatever IDs you're passing).
        compressor.compress(assignment)

...
</code></pre>
<p>To decompress assignments, we again must have a set of unique geometric
identifiers which match the assignments. We can then iterate over the
decompressed assignments as they're read out of the file.</p>
<pre><code>...

geoids = blocks["GEOID20"].astype(str)
ac = AssignmentCompressor(geoids, location="compressed-assignments.ac")

for assignment in ac.decompress():
    &lt;do whatever!&gt;

...
</code></pre>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>DISTRICT_DELIMITER</code></strong> :&ensp;<code>bytes</code></dt>
<dd>A bytestring which separates district
identifiers in an assignment.</dd>
<dt><strong><code>ASSIGNMENT_DELIMITER</code></strong> :&ensp;<code>bytes</code></dt>
<dd>A bytestring which separates assignments from
each other.</dd>
<dt><strong><code>CHUNK_DELIMITER</code></strong> :&ensp;<code>bytes</code></dt>
<dd>A bytestring which separates assignment chunks
from each other.</dd>
<dt><strong><code>CHUNK_SIZE</code></strong> :&ensp;<code>int</code></dt>
<dd>Default number of bytes read in from the IO stream at each
step.</dd>
<dt><strong><code>ENCODING</code></strong> :&ensp;<code>str</code></dt>
<dd>Default string encoding style.</dd>
<dt><strong><code>identifiers</code></strong></dt>
<dd>A sortable, iterable collection of unique items corresponding
to geographic identifiers.</dd>
<dt><strong><code>compressed</code></strong></dt>
<dd>A pandas <code>Index</code> containing the identifiers; this is used
to quickly perform vectorized identifier matchings, rather than using
traditional iterative methods.</dd>
<dt><strong><code>cache</code></strong></dt>
<dd>Collection of assignments to be compressed. Assignments are loaded
into the cache every time the <code>.compress()</code> method is called, and
is cleared whenever the length of the cache exceeds the window width.</dd>
<dt><strong><code>window</code></strong></dt>
<dd>Maximum cache length before the cache is compressed, written to
file, and emptied.</dd>
<dt><strong><code>default</code></strong></dt>
<dd>The default assignment which is updated each time an assignment
is passed to the compressor.</dd>
<dt><strong><code>location</code></strong></dt>
<dd>The place to which compressed data is written or read.</dd>
</dl>
<p>Creates <code><a title="evaltools.processing.AssignmentCompressor" href="#evaltools.processing.AssignmentCompressor">AssignmentCompressor</a></code> instance.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>identifiers</code></strong> :&ensp;<code>list</code></dt>
<dd>An iterable collection of string identifiers; any
assignment's keys must be a subset of <code>identifiers</code>.</dd>
<dt><strong><code>window</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>A positive integer representing the cache
window size. Defaults to cache.</dd>
<dt><strong><code>location</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The path to the compressed resource (read
or write). Defaults to <code>compressed.ac</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AssignmentCompressor:
    &#34;&#34;&#34;
    A class for compressing and decompressing lots of assignments very, very
    quickly. Intended for use with ``jsonlines``-like libraries (where assignments
    are read in line-by-line) or for network requests (where assignments are 
    retrieved one-by-one). When decompressing, yields ``dict``s where keys are
    in sorted order.

    The compression schema considers the set of unique identifiers, imposes an
    ordering (lexicographic order) on the identifiers, and matches the assignment
    to that ordering. We assign all unassigned units to ``&#34;-1&#34;`` and, once the
    default cache size is hit (or assignments are no longer being read in),
    compress all assignments in the cache. Assignments are read in and out in
    the same order, and the keys for each assignment are in the same order.

    Example:
        To compress assignments, we need a set of unique identifiers such that
        each identifier maps one geometric unit to one district.

            ...

            geoids = blocks[&#34;GEOID20&#34;].astype(str)
            ac = AssignmentCompressor(geoids, location=&#34;compressed-assignments.ac&#34;)

            with ac as compressor:
                for assignment in assignments:
                    # Here, ensure that all assignments have string keys and
                    # string values; also ensure that an assignment&#39;s keys are
                    # a subset of geoids (or whatever IDs you&#39;re passing).
                    compressor.compress(assignment)

            ...

        To decompress assignments, we again must have a set of unique geometric
        identifiers which match the assignments. We can then iterate over the
        decompressed assignments as they&#39;re read out of the file.

            ...

            geoids = blocks[&#34;GEOID20&#34;].astype(str)
            ac = AssignmentCompressor(geoids, location=&#34;compressed-assignments.ac&#34;)

            for assignment in ac.decompress():
                &lt;do whatever!&gt;

            ...

    Attributes:
        DISTRICT_DELIMITER (bytes): A bytestring which separates district
            identifiers in an assignment.
        ASSIGNMENT_DELIMITER (bytes): A bytestring which separates assignments from
            each other.
        CHUNK_DELIMITER (bytes): A bytestring which separates assignment chunks
            from each other.
        CHUNK_SIZE (int): Default number of bytes read in from the IO stream at each
            step.
        ENCODING (str): Default string encoding style.
        identifiers: A sortable, iterable collection of unique items corresponding
            to geographic identifiers.
        compressed: A pandas `Index` containing the identifiers; this is used
            to quickly perform vectorized identifier matchings, rather than using
            traditional iterative methods.
        cache: Collection of assignments to be compressed. Assignments are loaded
            into the cache every time the ``.compress()`` method is called, and
            is cleared whenever the length of the cache exceeds the window width.
        window: Maximum cache length before the cache is compressed, written to
            file, and emptied.
        default: The default assignment which is updated each time an assignment
            is passed to the compressor.
        location: The place to which compressed data is written or read.
    &#34;&#34;&#34;

    def __init__(self, identifiers, window=10, location=&#34;compressed.ac&#34;):
        &#34;&#34;&#34;
        Creates `AssignmentCompressor` instance.

        Args:
            identifiers (list): An iterable collection of string identifiers; any
                assignment&#39;s keys must be a subset of `identifiers`.
            window (int, optional): A positive integer representing the cache
                window size. Defaults to cache.
            location (str, optional): The path to the compressed resource (read
                or write). Defaults to `compressed.ac`.
        &#34;&#34;&#34;
        self.identifiers = SortedList(identifiers)
        self.default = frozenset(zip(self.identifiers, [&#34;-1&#34;]*len(self.identifiers)))
        self.cache = []
        self.location = location

        # Error to users if the window is nonexistent.
        if type(window) != int or window &lt;= 0:
            raise ValueError(&#34;Cache window width must be a positive integer.&#34;)

        self.window = window

        self.DISTRICT_DELIMITER = b&#34;,&#34;
        self.ASSIGNMENT_DELIMITER = b&#34;&lt;&lt;&lt;*&gt;&gt;&gt;&#34;
        self.CHUNK_DELIMITER = b&#34;(((*)))&#34;
        self.CHUNK_SIZE = 16384
        self.ENCODING = &#34;raw_unicode_escape&#34;

    def match(self, assignment) -&gt; SortedDict:
        &#34;&#34;&#34;
        Matches an assignment to an index (the set of geometric identifiers)
        and returns a `SortedDict`.

        Args:
            assignment (dict): Dictionary which matches geometric identifiers to
                districts. All keys and values in this dictionary must be strings.

        Returns:
            A `SortedDict` with identifiers matched ti district assignments.s

        &#34;&#34;&#34;
        # Create a dictionary which maps identifiers to `-1`, and update our
        # dictionary with assignment values.
        indexer = SortedDict(self.default)
        indexer.update(assignment)
        
        return indexer

    def __enter__(self):
        &#34;&#34;&#34;
        A simple context-management method. Allows the user to use `with`
        statements when compressing stuff so we don&#39;t have to worry about the
        user specifying the last item they&#39;ll be compressing.
        &#34;&#34;&#34;
        return self

    def __exit__(self, exc_type, exc_value, exc_tb):
        &#34;&#34;&#34;
        Teardown. Once we&#39;ve exited the `with` statement (i.e. the user&#39;s all done
        feeding items to the compressor) we can force the remaining items to be
        compressed and written to file.
        &#34;&#34;&#34;
        if self.cache: self._compress(force=True)

    def compress_all(self, assignments):
        &#34;&#34;&#34;
        Compresses all assignments in `assignments`.

        Args:
            assignments (list): List of dictionaries which match geometric identifiers
                to districts. All keys and values in these dictionaries must be
                strings.
        &#34;&#34;&#34;
        self.window = len(assignments)

        with self as ac:
            for assignment in assignments:
                ac.compress(assignment)

    def compress(self, assignment):
        &#34;&#34;&#34;
        Compresses the assignment `assignment` using `zlib`.

        Args:
            assignment (dict): Dictionary which matches geometric identifiers to districts.
                All keys and values in this dictionary must be strings.
        &#34;&#34;&#34;
        # If the user provides an empty assignment or the assignment&#39;s keys aren&#39;t
        # a subset of `identifiers`, warn the user and skip the assignment.
        skip = False

        if not assignment:
            skip = True
            print(&#34;`assignment` is empty; skipping.&#34;)

        if not set(assignment.keys()).issubset(self.identifiers):
            skip = True
            print(
                &#34;`assignment`&#39;s keys are not a subset of `identifiers`; skipping. &#34; + \
                &#34;Please ensure that all keys and values in `assignment` are strings.&#34;,
            )

        # Join the things on the district separator, encode the whole thing, and
        # encode according to the default encoding.
        if not skip:
            indexed = self.match(assignment)
            sep = self.DISTRICT_DELIMITER.decode()
            encoded = bytes(sep.join(indexed.values()).encode(self.ENCODING))

            # Compress.
            self.cache += [encoded]
            self._compress()

    def _compress(self, force=False):
        &#34;&#34;&#34;
        Private method which actually does the compression.

        Args:
            force: If truthy, then the length of the cache is ignored, the data
                in the cache are compressed, and the compressed data is written
                to file. ``force`` is truthy when teardown logic is entered
                (i.e. after ``__exit()__`` is called).
        &#34;&#34;&#34;
        # Check to see if the cache is full. If so, compress the data, write to
        # file, and reset the cache.
        if len(self.cache) == self.window or force:
            with open(self.location, &#34;ab&#34;) as writer:
                # Write compressed data to file.
                compressed = zlib.compress(
                    bytes(self.ASSIGNMENT_DELIMITER.join(self.cache))
                )
                writer.write(compressed)

                # We only forcibly write the chunk separator to file if we&#39;ve
                # entered teardown logic and the cache *is not empty*. If the
                # cache is empty when we&#39;re entering teardown logic, that means
                # (number of assignments compressed) == (window width), in which
                # case we&#39;ve reached the end of compression and should not write
                # a separator; doing so will produce an empty bytestring (which,
                # in turn, produces a dictionary with one key, corresponding to
                # a null assignment).
                if not force: writer.write(self.CHUNK_DELIMITER)

            # Reset the cache.
            self.cache = []

    def decompress(self):
        &#34;&#34;&#34;
        Decompresses the data at ``location``. A generator which ``yield``s
        assignments.

        Yields:
            Decompressed assignment dictionaries.
        &#34;&#34;&#34;
        # Open the compressed file. Then we read it in chunks, loading until
        # we hit our separator or until the end of the file.
        with open(self.location, &#34;rb&#34;) as _compressed_fin:
            for chunk in self._chunk(_compressed_fin):
                if not chunk: break
                for assignment in self._decompress(chunk): yield assignment

    def _chunk(self, stream):
        &#34;&#34;&#34;
        Private method for reading chunks from file without holding the entire
        file in memory. A generator for decompressed assignments.

        Args:
            stream: A ``BytesIO`` instance from which data is read.

        Yields:
            Buffered, compressed bytes to be fed into the decompressor.
        &#34;&#34;&#34;
        # Create a buffer.
        _buffer = []

        # Read until we hit the end of the file `yield`ing each chunk as we go.
        while True:
            # Read in a chunk of data.
            chunk = stream.read(self.CHUNK_SIZE)
            _buffer.append(chunk)

            # Check if the chunk has our delimiter in it. If it contains our
            # delimiter, then the buffer *up to the delimiter* contains compressed
            # assignments; this should be `yield`ed and decompressed. We only
            # want to get the part before the delimiter for decompression, but
            # retain the rest.
            if self.CHUNK_DELIMITER in chunk:
                _buffered_bytes = b&#34;&#34;.join(_buffer)
                part, _buffer_first = _buffered_bytes.split(self.CHUNK_DELIMITER, 1)
                _buffer = [_buffer_first]
                yield part

            # If the chunk&#39;s empty, `yield` the remaining buffer and return.
            if not chunk: yield b&#34;&#34;.join(_buffer); break

    def _decompress(self, chunk) -&gt; List[dict]:
        &#34;&#34;&#34;
        Private method which decompresses assignments.

        Args:
            chunk: Compressed, byte-encoded data representing ``window``
                assignments.

        Returns:
            List of decompressed assignment objects.
        &#34;&#34;&#34;
        # Decompress the chunk and split it on our delimiter.
        decompressed = zlib.decompress(chunk)
        decompressed_parts = decompressed.split(self.ASSIGNMENT_DELIMITER)
        
        # For each of the parts, decode the bytes, make them into lists, and
        # match them to GEOIDs.
        decoded_parts = [part.decode() for part in decompressed_parts]
        split_parts = [part.split(self.DISTRICT_DELIMITER.decode()) for part in decoded_parts]
        indexed_parts = [dict(zip(self.identifiers, part)) for part in split_parts]

        return indexed_parts</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="evaltools.processing.AssignmentCompressor.compress"><code class="name flex">
<span>def <span class="ident">compress</span></span>(<span>self, assignment)</span>
</code></dt>
<dd>
<div class="desc"><p>Compresses the assignment <code>assignment</code> using <code>zlib</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>assignment</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary which matches geometric identifiers to districts.
All keys and values in this dictionary must be strings.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compress(self, assignment):
    &#34;&#34;&#34;
    Compresses the assignment `assignment` using `zlib`.

    Args:
        assignment (dict): Dictionary which matches geometric identifiers to districts.
            All keys and values in this dictionary must be strings.
    &#34;&#34;&#34;
    # If the user provides an empty assignment or the assignment&#39;s keys aren&#39;t
    # a subset of `identifiers`, warn the user and skip the assignment.
    skip = False

    if not assignment:
        skip = True
        print(&#34;`assignment` is empty; skipping.&#34;)

    if not set(assignment.keys()).issubset(self.identifiers):
        skip = True
        print(
            &#34;`assignment`&#39;s keys are not a subset of `identifiers`; skipping. &#34; + \
            &#34;Please ensure that all keys and values in `assignment` are strings.&#34;,
        )

    # Join the things on the district separator, encode the whole thing, and
    # encode according to the default encoding.
    if not skip:
        indexed = self.match(assignment)
        sep = self.DISTRICT_DELIMITER.decode()
        encoded = bytes(sep.join(indexed.values()).encode(self.ENCODING))

        # Compress.
        self.cache += [encoded]
        self._compress()</code></pre>
</details>
</dd>
<dt id="evaltools.processing.AssignmentCompressor.compress_all"><code class="name flex">
<span>def <span class="ident">compress_all</span></span>(<span>self, assignments)</span>
</code></dt>
<dd>
<div class="desc"><p>Compresses all assignments in <code>assignments</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>assignments</code></strong> :&ensp;<code>list</code></dt>
<dd>List of dictionaries which match geometric identifiers
to districts. All keys and values in these dictionaries must be
strings.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compress_all(self, assignments):
    &#34;&#34;&#34;
    Compresses all assignments in `assignments`.

    Args:
        assignments (list): List of dictionaries which match geometric identifiers
            to districts. All keys and values in these dictionaries must be
            strings.
    &#34;&#34;&#34;
    self.window = len(assignments)

    with self as ac:
        for assignment in assignments:
            ac.compress(assignment)</code></pre>
</details>
</dd>
<dt id="evaltools.processing.AssignmentCompressor.decompress"><code class="name flex">
<span>def <span class="ident">decompress</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Decompresses the data at <code>location</code>. A generator which <code>yield</code>s
assignments.</p>
<h2 id="yields">Yields</h2>
<p>Decompressed assignment dictionaries.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def decompress(self):
    &#34;&#34;&#34;
    Decompresses the data at ``location``. A generator which ``yield``s
    assignments.

    Yields:
        Decompressed assignment dictionaries.
    &#34;&#34;&#34;
    # Open the compressed file. Then we read it in chunks, loading until
    # we hit our separator or until the end of the file.
    with open(self.location, &#34;rb&#34;) as _compressed_fin:
        for chunk in self._chunk(_compressed_fin):
            if not chunk: break
            for assignment in self._decompress(chunk): yield assignment</code></pre>
</details>
</dd>
<dt id="evaltools.processing.AssignmentCompressor.match"><code class="name flex">
<span>def <span class="ident">match</span></span>(<span>self, assignment) ‑> sortedcontainers.sorteddict.SortedDict</span>
</code></dt>
<dd>
<div class="desc"><p>Matches an assignment to an index (the set of geometric identifiers)
and returns a <code>SortedDict</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>assignment</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary which matches geometric identifiers to
districts. All keys and values in this dictionary must be strings.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A <code>SortedDict</code> with identifiers matched ti district assignments.s</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def match(self, assignment) -&gt; SortedDict:
    &#34;&#34;&#34;
    Matches an assignment to an index (the set of geometric identifiers)
    and returns a `SortedDict`.

    Args:
        assignment (dict): Dictionary which matches geometric identifiers to
            districts. All keys and values in this dictionary must be strings.

    Returns:
        A `SortedDict` with identifiers matched ti district assignments.s

    &#34;&#34;&#34;
    # Create a dictionary which maps identifiers to `-1`, and update our
    # dictionary with assignment values.
    indexer = SortedDict(self.default)
    indexer.update(assignment)
    
    return indexer</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="evaltools.processing.Submission"><code class="flex name class">
<span>class <span class="ident">Submission</span></span>
<span>(</span><span>**data: Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Provides a base model for data retrieved from districtr. Allows us to use
dot notation when accessing properties rather than dict notation.</p>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Submission(BaseModel):
    &#34;&#34;&#34;
    Provides a base model for data retrieved from districtr. Allows us to use
    dot notation when accessing properties rather than dict notation.
    &#34;&#34;&#34;
    link: str
    &#34;&#34;&#34;A districtr URL.&#34;&#34;&#34;
    plan: dict
    &#34;&#34;&#34;districtr plan object.&#34;&#34;&#34;
    id: str
    &#34;&#34;&#34;districtr identifier.&#34;&#34;&#34;
    units: str
    &#34;&#34;&#34;Unit identifier (e.g. `GEOID`).&#34;&#34;&#34;
    unitsType: str
    &#34;&#34;&#34;Unit type (e.g. `blocks20`, `blockgroup`, etc.)&#34;&#34;&#34;
    tileset: str
    &#34;&#34;&#34;Mapbox tileset URL.&#34;&#34;&#34;
    type: str
    &#34;&#34;&#34;Not sure.&#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="evaltools.processing.Submission.id"><code class="name">var <span class="ident">id</span> : str</code></dt>
<dd>
<div class="desc"><p>districtr identifier.</p></div>
</dd>
<dt id="evaltools.processing.Submission.link"><code class="name">var <span class="ident">link</span> : str</code></dt>
<dd>
<div class="desc"><p>A districtr URL.</p></div>
</dd>
<dt id="evaltools.processing.Submission.plan"><code class="name">var <span class="ident">plan</span> : dict</code></dt>
<dd>
<div class="desc"><p>districtr plan object.</p></div>
</dd>
<dt id="evaltools.processing.Submission.tileset"><code class="name">var <span class="ident">tileset</span> : str</code></dt>
<dd>
<div class="desc"><p>Mapbox tileset URL.</p></div>
</dd>
<dt id="evaltools.processing.Submission.type"><code class="name">var <span class="ident">type</span> : str</code></dt>
<dd>
<div class="desc"><p>Not sure.</p></div>
</dd>
<dt id="evaltools.processing.Submission.units"><code class="name">var <span class="ident">units</span> : str</code></dt>
<dd>
<div class="desc"><p>Unit identifier (e.g. <code>GEOID</code>).</p></div>
</dd>
<dt id="evaltools.processing.Submission.unitsType"><code class="name">var <span class="ident">unitsType</span> : str</code></dt>
<dd>
<div class="desc"><p>Unit type (e.g. <code>blocks20</code>, <code>blockgroup</code>, etc.)</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<!-- include a script for adding stuff to the end of proofs. -->
<script>
// Get all the proofs in the document.
proofs = document.getElementsByClassName("proof");
// For each of the proofs, attach a floating child element in the bottom-right
// corner.
for (var proof of proofs) {
// Create a proof-ending tombstone.
square = document.createElement("div");
square.className = "tombstone";
square.innerHTML = "◼️";
// Attach the tombstone to the proof.
proof.appendChild(square);
}
</script>
<header>
<a class="homelink" rel="home" title="evaltools" href="https://github.com/mggg/plan-evaluation-processing">
<style>
header > h1 { display: none; }
img.resize {
max-width: 80%;
max-height: 80%;
display: block;
margin: 0 auto;
}
div.proof {
border: 1px solid black;
padding: 0em 1em;
width: 90%;
margin: 1em auto;
}
.tombstone {
margin-top: -2em;
float: right;
}
</style>
<img class="resize" src="https://mggg.org/assets/logo.svg" alt="MGGG Logo">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="evaltools" href="../index.html">evaltools</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="evaltools.processing.URLs" href="URLs.html">evaltools.processing.URLs</a></code></li>
<li><code><a title="evaltools.processing.fetch" href="fetch.html">evaltools.processing.fetch</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="evaltools.processing.csvs" href="#evaltools.processing.csvs">csvs</a></code></li>
<li><code><a title="evaltools.processing.ids" href="#evaltools.processing.ids">ids</a></code></li>
<li><code><a title="evaltools.processing.one" href="#evaltools.processing.one">one</a></code></li>
<li><code><a title="evaltools.processing.remap" href="#evaltools.processing.remap">remap</a></code></li>
<li><code><a title="evaltools.processing.submissions" href="#evaltools.processing.submissions">submissions</a></code></li>
<li><code><a title="evaltools.processing.tabularized" href="#evaltools.processing.tabularized">tabularized</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="evaltools.processing.AssignmentCompressor" href="#evaltools.processing.AssignmentCompressor">AssignmentCompressor</a></code></h4>
<ul class="">
<li><code><a title="evaltools.processing.AssignmentCompressor.compress" href="#evaltools.processing.AssignmentCompressor.compress">compress</a></code></li>
<li><code><a title="evaltools.processing.AssignmentCompressor.compress_all" href="#evaltools.processing.AssignmentCompressor.compress_all">compress_all</a></code></li>
<li><code><a title="evaltools.processing.AssignmentCompressor.decompress" href="#evaltools.processing.AssignmentCompressor.decompress">decompress</a></code></li>
<li><code><a title="evaltools.processing.AssignmentCompressor.match" href="#evaltools.processing.AssignmentCompressor.match">match</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="evaltools.processing.Submission" href="#evaltools.processing.Submission">Submission</a></code></h4>
<ul class="two-column">
<li><code><a title="evaltools.processing.Submission.id" href="#evaltools.processing.Submission.id">id</a></code></li>
<li><code><a title="evaltools.processing.Submission.link" href="#evaltools.processing.Submission.link">link</a></code></li>
<li><code><a title="evaltools.processing.Submission.plan" href="#evaltools.processing.Submission.plan">plan</a></code></li>
<li><code><a title="evaltools.processing.Submission.tileset" href="#evaltools.processing.Submission.tileset">tileset</a></code></li>
<li><code><a title="evaltools.processing.Submission.type" href="#evaltools.processing.Submission.type">type</a></code></li>
<li><code><a title="evaltools.processing.Submission.units" href="#evaltools.processing.Submission.units">units</a></code></li>
<li><code><a title="evaltools.processing.Submission.unitsType" href="#evaltools.processing.Submission.unitsType">unitsType</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>