<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>evaltools.data.fetch API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>evaltools.data.fetch</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import requests
import json
import io
from datetime import datetime
from pydantic import BaseModel
from typing import Tuple, List, Union

from .URLs import ids, csvs, one


class Submission(BaseModel):
    &#34;&#34;&#34;
    Provides a base model for data retrieved from districtr. Allows us to use
    dot notation when accessing properties rather than dict notation.
    &#34;&#34;&#34;
    link: str
    &#34;&#34;&#34;A districtr URL.&#34;&#34;&#34;
    plan: dict
    &#34;&#34;&#34;districtr plan object.&#34;&#34;&#34;
    id: str
    &#34;&#34;&#34;districtr identifier.&#34;&#34;&#34;
    units: str
    &#34;&#34;&#34;Unit identifier (e.g. `GEOID`).&#34;&#34;&#34;
    unitsType: str
    &#34;&#34;&#34;Unit type (e.g. `blocks20`, `blockgroup`, etc.)&#34;&#34;&#34;
    tileset: str
    &#34;&#34;&#34;Mapbox tileset URL.&#34;&#34;&#34;
    type: str
    &#34;&#34;&#34;Not sure.&#34;&#34;&#34;


def tabularized(state, submissions) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    &#34;&#34;&#34;
    Returns districtr submission information in a tabular format.

    Args:
        state (State): `us.State` object (e.g. `us.states.WI`).
        submissions (list): List of `Submission` objects returned from a call to
            `submissions`.

    Returns:
        Three dataframes corresponding to plan-based submissions, COI-based
        submissions, and written submissions to the provided state.

    Example:
        Prototypical example usage.

            import us
            from evaltools.retrieve import submissions, tabularized

            # Set the state.
            state = us.states.WI

            # Retrieve the raw districtr submissions, then tabularize them.
            subs = submissions(state)
            plans, cois, written = tabularized(state, subs)

    &#34;&#34;&#34;
    # Sort submissions. (Not sure why this is necessary? Holdover from previous
    # fetching code.)
    submissions = list(sorted(submissions, key=lambda s: s.id))

    # Categorize into three categories: plan submissions, COI submissions, and
    # written submissions (which are ignored as they don&#39;t appear in the list
    # of submissions).
    _plans = [s.dict() for s in submissions if s.type == &#34;plan&#34;]
    _cois = [s.dict() for s in submissions if s.type == &#34;coi&#34;]

    # Create preliminary dataframes so we can do safe `merge`s rather than rely
    # explicitly on sorting; this also allows us to specify a sample size if
    # we&#39;re only looking to sample a specific number of plans.
    subset_plans = pd.DataFrame.from_records(_plans)
    subset_cois = pd.DataFrame.from_records(_cois)

    # Get appropriate URLs and create dataframes.
    plans_url = csvs(state)
    cois_url = csvs(state, ptype=&#34;coi&#34;)
    written_url = csvs(state, ptype=&#34;written&#34;)

    plans = as_dataframe(plans_url)
    cois = as_dataframe(cois_url)
    writtens = as_dataframe(written_url)

    # Adjust column contents for the plan and COI dataframes.
    for universe in [plans, cois]:
        # Adjust the `link` column type and create an `id` column from it.
        universe[&#34;link&#34;] = universe[&#34;link&#34;].astype(str)
        universe[&#34;id&#34;] = parse_id(universe[&#34;link&#34;])

    # Adjust column contents for all dataframes.
    for df in [plans, cois, writtens]:
        df[&#34;datetime&#34;] = parse_datetime(df[&#34;datetime&#34;])

    # Add the retrieved plan data to the dataframes *if the subset dataframes
    # contain items*.
    if not subset_plans.empty:
        plans = plans.merge(subset_plans, on=&#34;id&#34;)
    else:
        plans = pd.DataFrame()
    if not subset_cois.empty:
        cois = cois.merge(subset_cois, on=&#34;id&#34;)
    else:
        cois = pd.DataFrame()

    # Drop bad columns and rename. Not sure why we have to `inplace` things here,
    # but... fine.
    for df in [plans, cois]:
        if not df.empty:
            # Remove columns we don&#39;t necessarily care about.
            for col in [&#34;type_x&#34;, &#34;link_x&#34;, &#34;coalition&#34;]:
                if col in list(df):
                    df.drop(col, axis=1, inplace=True)

            # Rename the columns we do care about.
            df.rename({&#34;type_y&#34;: &#34;type&#34;, &#34;link_y&#34;: &#34;link&#34;}, axis=1, inplace=True)

    return plans, cois, writtens


def submissions(state, sample=None) -&gt; List[Submission]:
    &#34;&#34;&#34;
    Retrieves raw districtr objects; this includes both plan- and COI-based
    submissions.

    Args:
        state (State): `us.State` object (e.g. `us.states.WI`).
        sample (int, optional): The number of sample plans to retrieve.

    Returns:
        A list of `Submissions`, either to be interpreted raw or tabularized.
    &#34;&#34;&#34;
    # Get the appropriate URL and send the request. Made some basic ASCII art with
    # the second three variable names... it&#39;s like the request is loading letter
    # by letter.
    url = ids(state)
    __w = requests.get(url).text
    _aw = json.loads(__w)[&#34;ids&#34;]
    raw = _aw[:sample] if sample else _aw

    # Create `Submission` objects for each of the retrieved objects. Getting the
    # individual plans is the bottleneck here, and unfortunately we can&#39;t retrieve
    # them in bulk (... or can we?).
    submissions = []
    for entity in raw:
        # Retrieve the required data points.
        identifier = parse_id(entity[&#34;link&#34;], df=False)
        districtr = individual(identifier)

        # Force all plan keys and values to strings.
        try:
            plan = {
                str(k): str(v) if not isinstance(v, list) else str(v[0])
                for k, v in districtr[&#34;plan&#34;][&#34;assignment&#34;].items()
            }
            units = districtr[&#34;plan&#34;][&#34;units&#34;][&#34;name&#34;]
            unitsType = districtr[&#34;plan&#34;][&#34;units&#34;][&#34;unitType&#34;]
            tileset = districtr[&#34;plan&#34;][&#34;units&#34;][&#34;tilesets&#34;][0][&#34;sourceLayer&#34;]

            # Create a new Submission.
            submissions.append(Submission(
                link=entity[&#34;link&#34;],
                id=identifier,
                plan=plan,
                units=units,
                unitsType=unitsType,
                tileset=tileset,
                type=entity[&#34;type&#34;]
            ))
        except BaseException:
            pass

    return submissions


def as_dataframe(url) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Retrieves encoded submission data from the provided URL and parses it into
    a pandas `DataFrame`.

    Args:
        url (str): Wherever we&#39;re getting things from.
    &#34;&#34;&#34;
    raw = requests.get(url).content
    return pd.read_csv(io.StringIO(raw.decode(&#34;utf-8&#34;)), parse_dates=True)


def individual(identifier) -&gt; dict:
    &#34;&#34;&#34;
    Retrieves districtr data for an individual plan.

    Args:
        identifier (str): districtr identifier for an individual plan.

    Returns:
        districtr plan object (as a dictionary).
    &#34;&#34;&#34;
    raw = requests.get(one(identifier))
    return json.loads(raw.text)


def parse_id(link, df=True) -&gt; Union[str, pd.Series]:
    &#34;&#34;&#34;
    Given a districtr link, parse out the districtr identifier.

    Args:
        l (str): districtr url containing the districtr ID of the provided plan.
        df (bool, optional): If `l` is a dataframe, then we use pandas string
            operations rather than built-in ones.

    Returns:
        districtr ID.
    &#34;&#34;&#34;
    if df:
        return link.str.split(&#34;/&#34;).str[-1].str.split(&#34;?&#34;).str[0]
    return link.split(&#34;/&#34;)[-1].split(&#34;?&#34;)[0]


def parse_datetime(d) -&gt; pd.Series:
    &#34;&#34;&#34;
    Parses the timestamps in the dataframe returned by `as_dataframe()`.

    Args:
        d (str): Column of the dataframe containing timestamps.

    Returns:
        `d` with its datetimes parsed correctly.
    &#34;&#34;&#34;
    # Parse datetimes.
    prefix = d.str.split(&#34;+&#34;).str[0]
    suffix = d.str.split(&#34;+&#34;).str[1].str.split(&#34; &#34;).str[0]
    dt = prefix + &#34; +&#34; + suffix

    # Convert datetimes.
    return dt.apply(lambda r: datetime.strptime(r, &#34;%a %b %d %Y %X %Z %z&#34;))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="evaltools.data.fetch.as_dataframe"><code class="name flex">
<span>def <span class="ident">as_dataframe</span></span>(<span>url) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieves encoded submission data from the provided URL and parses it into
a pandas <code>DataFrame</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>Wherever we're getting things from.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def as_dataframe(url) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Retrieves encoded submission data from the provided URL and parses it into
    a pandas `DataFrame`.

    Args:
        url (str): Wherever we&#39;re getting things from.
    &#34;&#34;&#34;
    raw = requests.get(url).content
    return pd.read_csv(io.StringIO(raw.decode(&#34;utf-8&#34;)), parse_dates=True)</code></pre>
</details>
</dd>
<dt id="evaltools.data.fetch.individual"><code class="name flex">
<span>def <span class="ident">individual</span></span>(<span>identifier) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieves districtr data for an individual plan.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>identifier</code></strong> :&ensp;<code>str</code></dt>
<dd>districtr identifier for an individual plan.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>districtr plan object (as a dictionary).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def individual(identifier) -&gt; dict:
    &#34;&#34;&#34;
    Retrieves districtr data for an individual plan.

    Args:
        identifier (str): districtr identifier for an individual plan.

    Returns:
        districtr plan object (as a dictionary).
    &#34;&#34;&#34;
    raw = requests.get(one(identifier))
    return json.loads(raw.text)</code></pre>
</details>
</dd>
<dt id="evaltools.data.fetch.parse_datetime"><code class="name flex">
<span>def <span class="ident">parse_datetime</span></span>(<span>d) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"><p>Parses the timestamps in the dataframe returned by <code><a title="evaltools.data.fetch.as_dataframe" href="#evaltools.data.fetch.as_dataframe">as_dataframe()</a></code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>d</code></strong> :&ensp;<code>str</code></dt>
<dd>Column of the dataframe containing timestamps.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code>d</code> with its datetimes parsed correctly.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_datetime(d) -&gt; pd.Series:
    &#34;&#34;&#34;
    Parses the timestamps in the dataframe returned by `as_dataframe()`.

    Args:
        d (str): Column of the dataframe containing timestamps.

    Returns:
        `d` with its datetimes parsed correctly.
    &#34;&#34;&#34;
    # Parse datetimes.
    prefix = d.str.split(&#34;+&#34;).str[0]
    suffix = d.str.split(&#34;+&#34;).str[1].str.split(&#34; &#34;).str[0]
    dt = prefix + &#34; +&#34; + suffix

    # Convert datetimes.
    return dt.apply(lambda r: datetime.strptime(r, &#34;%a %b %d %Y %X %Z %z&#34;))</code></pre>
</details>
</dd>
<dt id="evaltools.data.fetch.parse_id"><code class="name flex">
<span>def <span class="ident">parse_id</span></span>(<span>link, df=True) ‑> Union[str, pandas.core.series.Series]</span>
</code></dt>
<dd>
<div class="desc"><p>Given a districtr link, parse out the districtr identifier.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>l</code></strong> :&ensp;<code>str</code></dt>
<dd>districtr url containing the districtr ID of the provided plan.</dd>
<dt><strong><code>df</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>l</code> is a dataframe, then we use pandas string
operations rather than built-in ones.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>districtr ID.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_id(link, df=True) -&gt; Union[str, pd.Series]:
    &#34;&#34;&#34;
    Given a districtr link, parse out the districtr identifier.

    Args:
        l (str): districtr url containing the districtr ID of the provided plan.
        df (bool, optional): If `l` is a dataframe, then we use pandas string
            operations rather than built-in ones.

    Returns:
        districtr ID.
    &#34;&#34;&#34;
    if df:
        return link.str.split(&#34;/&#34;).str[-1].str.split(&#34;?&#34;).str[0]
    return link.split(&#34;/&#34;)[-1].split(&#34;?&#34;)[0]</code></pre>
</details>
</dd>
<dt id="evaltools.data.fetch.submissions"><code class="name flex">
<span>def <span class="ident">submissions</span></span>(<span>state, sample=None) ‑> List[<a title="evaltools.data.fetch.Submission" href="#evaltools.data.fetch.Submission">Submission</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieves raw districtr objects; this includes both plan- and COI-based
submissions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>state</code></strong> :&ensp;<code>State</code></dt>
<dd><code>us.State</code> object (e.g. <code>us.states.WI</code>).</dd>
<dt><strong><code>sample</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of sample plans to retrieve.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A list of <code>Submissions</code>, either to be interpreted raw or tabularized.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def submissions(state, sample=None) -&gt; List[Submission]:
    &#34;&#34;&#34;
    Retrieves raw districtr objects; this includes both plan- and COI-based
    submissions.

    Args:
        state (State): `us.State` object (e.g. `us.states.WI`).
        sample (int, optional): The number of sample plans to retrieve.

    Returns:
        A list of `Submissions`, either to be interpreted raw or tabularized.
    &#34;&#34;&#34;
    # Get the appropriate URL and send the request. Made some basic ASCII art with
    # the second three variable names... it&#39;s like the request is loading letter
    # by letter.
    url = ids(state)
    __w = requests.get(url).text
    _aw = json.loads(__w)[&#34;ids&#34;]
    raw = _aw[:sample] if sample else _aw

    # Create `Submission` objects for each of the retrieved objects. Getting the
    # individual plans is the bottleneck here, and unfortunately we can&#39;t retrieve
    # them in bulk (... or can we?).
    submissions = []
    for entity in raw:
        # Retrieve the required data points.
        identifier = parse_id(entity[&#34;link&#34;], df=False)
        districtr = individual(identifier)

        # Force all plan keys and values to strings.
        try:
            plan = {
                str(k): str(v) if not isinstance(v, list) else str(v[0])
                for k, v in districtr[&#34;plan&#34;][&#34;assignment&#34;].items()
            }
            units = districtr[&#34;plan&#34;][&#34;units&#34;][&#34;name&#34;]
            unitsType = districtr[&#34;plan&#34;][&#34;units&#34;][&#34;unitType&#34;]
            tileset = districtr[&#34;plan&#34;][&#34;units&#34;][&#34;tilesets&#34;][0][&#34;sourceLayer&#34;]

            # Create a new Submission.
            submissions.append(Submission(
                link=entity[&#34;link&#34;],
                id=identifier,
                plan=plan,
                units=units,
                unitsType=unitsType,
                tileset=tileset,
                type=entity[&#34;type&#34;]
            ))
        except BaseException:
            pass

    return submissions</code></pre>
</details>
</dd>
<dt id="evaltools.data.fetch.tabularized"><code class="name flex">
<span>def <span class="ident">tabularized</span></span>(<span>state, submissions) ‑> Tuple[pandas.core.frame.DataFrame, pandas.core.frame.DataFrame, pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns districtr submission information in a tabular format.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>state</code></strong> :&ensp;<code>State</code></dt>
<dd><code>us.State</code> object (e.g. <code>us.states.WI</code>).</dd>
<dt><strong><code>submissions</code></strong> :&ensp;<code>list</code></dt>
<dd>List of <code><a title="evaltools.data.fetch.Submission" href="#evaltools.data.fetch.Submission">Submission</a></code> objects returned from a call to
<code><a title="evaltools.data.fetch.submissions" href="#evaltools.data.fetch.submissions">submissions()</a></code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Three dataframes corresponding to plan-based submissions, COI-based
submissions, and written submissions to the provided state.</p>
<h2 id="example">Example</h2>
<p>Prototypical example usage.</p>
<pre><code>import us
from evaltools.retrieve import submissions, tabularized

# Set the state.
state = us.states.WI

# Retrieve the raw districtr submissions, then tabularize them.
subs = submissions(state)
plans, cois, written = tabularized(state, subs)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tabularized(state, submissions) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    &#34;&#34;&#34;
    Returns districtr submission information in a tabular format.

    Args:
        state (State): `us.State` object (e.g. `us.states.WI`).
        submissions (list): List of `Submission` objects returned from a call to
            `submissions`.

    Returns:
        Three dataframes corresponding to plan-based submissions, COI-based
        submissions, and written submissions to the provided state.

    Example:
        Prototypical example usage.

            import us
            from evaltools.retrieve import submissions, tabularized

            # Set the state.
            state = us.states.WI

            # Retrieve the raw districtr submissions, then tabularize them.
            subs = submissions(state)
            plans, cois, written = tabularized(state, subs)

    &#34;&#34;&#34;
    # Sort submissions. (Not sure why this is necessary? Holdover from previous
    # fetching code.)
    submissions = list(sorted(submissions, key=lambda s: s.id))

    # Categorize into three categories: plan submissions, COI submissions, and
    # written submissions (which are ignored as they don&#39;t appear in the list
    # of submissions).
    _plans = [s.dict() for s in submissions if s.type == &#34;plan&#34;]
    _cois = [s.dict() for s in submissions if s.type == &#34;coi&#34;]

    # Create preliminary dataframes so we can do safe `merge`s rather than rely
    # explicitly on sorting; this also allows us to specify a sample size if
    # we&#39;re only looking to sample a specific number of plans.
    subset_plans = pd.DataFrame.from_records(_plans)
    subset_cois = pd.DataFrame.from_records(_cois)

    # Get appropriate URLs and create dataframes.
    plans_url = csvs(state)
    cois_url = csvs(state, ptype=&#34;coi&#34;)
    written_url = csvs(state, ptype=&#34;written&#34;)

    plans = as_dataframe(plans_url)
    cois = as_dataframe(cois_url)
    writtens = as_dataframe(written_url)

    # Adjust column contents for the plan and COI dataframes.
    for universe in [plans, cois]:
        # Adjust the `link` column type and create an `id` column from it.
        universe[&#34;link&#34;] = universe[&#34;link&#34;].astype(str)
        universe[&#34;id&#34;] = parse_id(universe[&#34;link&#34;])

    # Adjust column contents for all dataframes.
    for df in [plans, cois, writtens]:
        df[&#34;datetime&#34;] = parse_datetime(df[&#34;datetime&#34;])

    # Add the retrieved plan data to the dataframes *if the subset dataframes
    # contain items*.
    if not subset_plans.empty:
        plans = plans.merge(subset_plans, on=&#34;id&#34;)
    else:
        plans = pd.DataFrame()
    if not subset_cois.empty:
        cois = cois.merge(subset_cois, on=&#34;id&#34;)
    else:
        cois = pd.DataFrame()

    # Drop bad columns and rename. Not sure why we have to `inplace` things here,
    # but... fine.
    for df in [plans, cois]:
        if not df.empty:
            # Remove columns we don&#39;t necessarily care about.
            for col in [&#34;type_x&#34;, &#34;link_x&#34;, &#34;coalition&#34;]:
                if col in list(df):
                    df.drop(col, axis=1, inplace=True)

            # Rename the columns we do care about.
            df.rename({&#34;type_y&#34;: &#34;type&#34;, &#34;link_y&#34;: &#34;link&#34;}, axis=1, inplace=True)

    return plans, cois, writtens</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="evaltools.data.fetch.Submission"><code class="flex name class">
<span>class <span class="ident">Submission</span></span>
<span>(</span><span>**data: Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Provides a base model for data retrieved from districtr. Allows us to use
dot notation when accessing properties rather than dict notation.</p>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Submission(BaseModel):
    &#34;&#34;&#34;
    Provides a base model for data retrieved from districtr. Allows us to use
    dot notation when accessing properties rather than dict notation.
    &#34;&#34;&#34;
    link: str
    &#34;&#34;&#34;A districtr URL.&#34;&#34;&#34;
    plan: dict
    &#34;&#34;&#34;districtr plan object.&#34;&#34;&#34;
    id: str
    &#34;&#34;&#34;districtr identifier.&#34;&#34;&#34;
    units: str
    &#34;&#34;&#34;Unit identifier (e.g. `GEOID`).&#34;&#34;&#34;
    unitsType: str
    &#34;&#34;&#34;Unit type (e.g. `blocks20`, `blockgroup`, etc.)&#34;&#34;&#34;
    tileset: str
    &#34;&#34;&#34;Mapbox tileset URL.&#34;&#34;&#34;
    type: str
    &#34;&#34;&#34;Not sure.&#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="evaltools.data.fetch.Submission.id"><code class="name">var <span class="ident">id</span> : str</code></dt>
<dd>
<div class="desc"><p>districtr identifier.</p></div>
</dd>
<dt id="evaltools.data.fetch.Submission.link"><code class="name">var <span class="ident">link</span> : str</code></dt>
<dd>
<div class="desc"><p>A districtr URL.</p></div>
</dd>
<dt id="evaltools.data.fetch.Submission.plan"><code class="name">var <span class="ident">plan</span> : dict</code></dt>
<dd>
<div class="desc"><p>districtr plan object.</p></div>
</dd>
<dt id="evaltools.data.fetch.Submission.tileset"><code class="name">var <span class="ident">tileset</span> : str</code></dt>
<dd>
<div class="desc"><p>Mapbox tileset URL.</p></div>
</dd>
<dt id="evaltools.data.fetch.Submission.type"><code class="name">var <span class="ident">type</span> : str</code></dt>
<dd>
<div class="desc"><p>Not sure.</p></div>
</dd>
<dt id="evaltools.data.fetch.Submission.units"><code class="name">var <span class="ident">units</span> : str</code></dt>
<dd>
<div class="desc"><p>Unit identifier (e.g. <code>GEOID</code>).</p></div>
</dd>
<dt id="evaltools.data.fetch.Submission.unitsType"><code class="name">var <span class="ident">unitsType</span> : str</code></dt>
<dd>
<div class="desc"><p>Unit type (e.g. <code>blocks20</code>, <code>blockgroup</code>, etc.)</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<!-- include a script for adding stuff to the end of proofs. -->
<script>
// Get all the proofs in the document.
proofs = document.getElementsByClassName("proof");
// For each of the proofs, attach a floating child element in the bottom-right
// corner.
for (var proof of proofs) {
// Create a proof-ending tombstone.
square = document.createElement("div");
square.className = "tombstone";
square.innerHTML = "◼️";
// Attach the tombstone to the proof.
proof.appendChild(square);
}
</script>
<header>
<a class="homelink" rel="home" title="evaltools" href="https://github.com/mggg/plan-evaluation-processing">
<style>
header > h1 { display: none; }
img.resize {
max-width: 80%;
max-height: 80%;
display: block;
margin: 0 auto;
}
div.proof {
border: 1px solid black;
padding: 0em 1em;
width: 90%;
margin: 1em auto;
}
.tombstone {
margin-top: -2em;
float: right;
}
</style>
<img class="resize" src="https://mggg.org/assets/logo.svg" alt="MGGG Logo">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="evaltools.data" href="index.html">evaltools.data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="evaltools.data.fetch.as_dataframe" href="#evaltools.data.fetch.as_dataframe">as_dataframe</a></code></li>
<li><code><a title="evaltools.data.fetch.individual" href="#evaltools.data.fetch.individual">individual</a></code></li>
<li><code><a title="evaltools.data.fetch.parse_datetime" href="#evaltools.data.fetch.parse_datetime">parse_datetime</a></code></li>
<li><code><a title="evaltools.data.fetch.parse_id" href="#evaltools.data.fetch.parse_id">parse_id</a></code></li>
<li><code><a title="evaltools.data.fetch.submissions" href="#evaltools.data.fetch.submissions">submissions</a></code></li>
<li><code><a title="evaltools.data.fetch.tabularized" href="#evaltools.data.fetch.tabularized">tabularized</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="evaltools.data.fetch.Submission" href="#evaltools.data.fetch.Submission">Submission</a></code></h4>
<ul class="two-column">
<li><code><a title="evaltools.data.fetch.Submission.id" href="#evaltools.data.fetch.Submission.id">id</a></code></li>
<li><code><a title="evaltools.data.fetch.Submission.link" href="#evaltools.data.fetch.Submission.link">link</a></code></li>
<li><code><a title="evaltools.data.fetch.Submission.plan" href="#evaltools.data.fetch.Submission.plan">plan</a></code></li>
<li><code><a title="evaltools.data.fetch.Submission.tileset" href="#evaltools.data.fetch.Submission.tileset">tileset</a></code></li>
<li><code><a title="evaltools.data.fetch.Submission.type" href="#evaltools.data.fetch.Submission.type">type</a></code></li>
<li><code><a title="evaltools.data.fetch.Submission.units" href="#evaltools.data.fetch.Submission.units">units</a></code></li>
<li><code><a title="evaltools.data.fetch.Submission.unitsType" href="#evaltools.data.fetch.Submission.unitsType">unitsType</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>