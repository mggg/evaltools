{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e41ea4-3847-4c10-96c6-c32f94bb6d8b",
   "metadata": {},
   "source": [
    "## scoring\n",
    "### for scoring districting plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ab0d9b-528e-4ba5-b476-c7c3cbf9ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gerrychain import Graph, Partition, Election\n",
    "from gerrytools.scoring import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1f5f8-0ca5-4003-971d-1019d3ff3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d83e0-1e7f-4bab-aa72-88814f3a94d6",
   "metadata": {},
   "source": [
    "All of our scores are functions that take a GerryChain `Partition` and produce either a numerical (plan-wide) score or a mapping from district or election IDs to numeric scores. For our examples, we will use a 2020 Maryland VTD shapefile to build our underlying dual graph, since the shapefile has demographic and electoral information that our scores will rely on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9219c59-4f79-4ee0-b703-3b76f1341416",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "graph = Graph.from_file(\"data/MD_vtd20/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472fff9-a5d0-4841-9ae3-ba4ecf3de32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "elections = [\"PRES12\", \"SEN12\", \"GOV14\", \"AG14\", \"COMP14\", \n",
    "             \"PRES16\", \"SEN16\", \"GOV18\", \"SEN18\", \"AG18\", \"COMP18\"]\n",
    "\n",
    "# use our list of elections ablve to create `Election` updaters for each contest\n",
    "# Ex: in our shapefile, the column `PRES12R` refers to the votes Mitt \n",
    "# Romney (R) received in the 2012 Presidential general election\n",
    "updaters = {}\n",
    "for e in elections:\n",
    "    updaters[e] = Election(e, {\"Dem\": e+\"D\", \"Rep\": e+\"R\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a89ffc-f941-447c-a770-463e24f6a521",
   "metadata": {},
   "source": [
    "The `demographic_updaters()` function returns a dictionary of `Tally` updaters that track the number of people of a given demographic group. You can pass as a list with as many demographic groups as you wish (example below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7187565-ea2c-4790-b43b-7d0bf63bb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_updaters([\"TOTPOP20\", \"VAP20\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f832170-d801-43fc-8302-9d39ec3fefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add updaters that track total population, total voting age population, \n",
    "# and Black and Hispanic voting age population\n",
    "updaters.update(demographic_updaters([\"TOTPOP20\", \"VAP20\", \"BVAP20\", \"HVAP20\"]))\n",
    "\n",
    "# create the partition on which we'll generate scores\n",
    "# since `MD_CD_example.csv` is a CSV with `GEOID20` -> district assignment,\n",
    "# we need to replace the `GEOID20`s with integer node labels to match the graph's nodes.\n",
    "geoid_to_assignment = pd.read_csv(\"data/MD_CD_example.csv\", header=None).set_index(0).to_dict()[1]\n",
    "assignment = {n: geoid_to_assignment[graph.nodes[n][\"GEOID20\"]] for n in graph.nodes}\n",
    "partition = Partition(graph, assignment, updaters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a83cc9-884f-4ec1-b9d7-bf38728eb4ca",
   "metadata": {},
   "source": [
    "### partisan scores\n",
    "All our partisan scores require at least a list of elections (we'll use our `elections` list defined above). Some of them additionally require the user to specify a POV party (in our case, either `Dem` or `Rep`). All of these partisan scores return a dictionary that maps election names to the score for that election; it is up to the user to aggregate (often by summing or averaging) the scores across every election. For a simple example, let's use the score function that returns the number of Democratic seats won in each election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3c3c2-cc61-412a-a87a-1237eb45da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "seats(elections, \"Dem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dbad43-0d03-4bed-bb47-fdeec6007737",
   "metadata": {},
   "source": [
    "Note that the output of `seats(elections, \"Dem\")` is of type `Score`, which functions like a Python `namedtuple`: for any object `x` of type `Score`, `x.name` returns the name of the score, and `x.apply` returns a function that takes a `Partition` as input and returns the score. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa022f-b032-4116-8766-3e120907a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "seats(elections, \"Dem\").name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0d4c9-fa81-486f-b858-10d92634b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seats(elections, \"Dem\").apply(partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfc8a5-b7ad-4fb6-8241-b5a256576a85",
   "metadata": {},
   "source": [
    "Note that we can easily find the number of Republican seats like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451edac-5641-4afd-990b-116ac5ac3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "seats(elections, \"Rep\").apply(partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0865f-2e0e-4f23-a315-3829f5d07306",
   "metadata": {},
   "source": [
    "Moreover, we can pass `mean=True` to return the average of the score over all elections, rather than a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb0e46-d83d-4d71-92cc-e37a923b3845",
   "metadata": {},
   "outputs": [],
   "source": [
    "seats(elections, \"Rep\", mean=True).apply(partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ba216-07d9-457d-9c7c-a3f648e25b1b",
   "metadata": {},
   "source": [
    "Some partisan scores (`mean_median`, `efficiency_gap`, `partisan_bias`, `partisan_gini`) do not require the user to specify the POV party in the call. This is not because there isn't a POV party, but because these functions call GerryChain functions that automatically set the POV party to be the **first** party listed in the updater for that election. Since we always list `Dem` first in this notebook, this means `Dem` will be the POV party for these scores— but this is something you should keep in mind when setting up your updaters and your partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1150b377-f90c-4a1f-a875-62716ad1d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive values denote an advantage for the POV party\n",
    "efficiency_gap(elections).apply(partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e11b9d-1350-4e57-8dd1-5dd56b7b350a",
   "metadata": {},
   "source": [
    "If you know you want to use a lot of scores, it can be helpful to make a list of the scores of interest, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f740c4d-4812-4d31-9250-3d912d1ff81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "partisan_scores = [\n",
    "    seats(elections, \"Dem\"),\n",
    "    seats(elections, \"Rep\"),\n",
    "    signed_proportionality(elections, \"Dem\", mean=True),\n",
    "    absolute_proportionality(elections, \"Dem\", mean=True),\n",
    "    efficiency_gap(elections, mean=True),\n",
    "    mean_median(elections),\n",
    "    partisan_bias(elections),\n",
    "    partisan_gini(elections),\n",
    "    # Note that `eguia` takes several more arguments — see the documentation for more details\n",
    "    eguia(elections, \"Dem\", graph, updaters, \"COUNTYFP20\", \"TOTPOP20\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bd00f5-063e-4979-86c1-dd52ca74a0ce",
   "metadata": {},
   "source": [
    "Now, we can make use of the `summarize()` function to evaluate all the scores on this partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759918a-795c-43f9-809e-01cf99b7b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "partisan_dictionary = summarize(partition, partisan_scores)\n",
    "partisan_dictionary[\"mean_median\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c741bf9-7def-43d6-ba2e-d44e3784e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "partisan_dictionary[\"mean_efficiency_gap\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3d4d5-9bb3-457f-9811-e79b37b1a8fe",
   "metadata": {},
   "source": [
    "### demographic scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e213d-3ea1-459b-87c2-faec27892e1b",
   "metadata": {},
   "source": [
    "Our demographic scores return a dictionary that maps districts to demographic information, either population counts or shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8bd648-fa19-4d16-b4ae-771f52905753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `demographic_tallies()` takes a list of the demographics you'd like to tally\n",
    "tally_scores = demographic_tallies([\"TOTPOP20\", \"BVAP20\", \"HVAP20\"])\n",
    "tally_dictionary = summarize(partition, tally_scores)\n",
    "tally_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6529c95a-17ba-4be5-a13d-2b551f025505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `demographic_shares()` takes a dictionary where each key is a total demographic column\n",
    "# that will be used as the denominator in the share (usually either `TOTPOP20` or `VAP20`)\n",
    "# and each value is a list of demographics on which you'd like to compute shares\n",
    "share_scores = demographic_shares({\"VAP20\": [\"BVAP20\", \"HVAP20\"]})\n",
    "share_dictionary = summarize(partition, share_scores)\n",
    "share_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465cb09f-314c-46f3-8304-b78b895b4b49",
   "metadata": {},
   "source": [
    "#### Two things to note:\n",
    "\n",
    "Both `demographic_tallies()` and `demographic_shares()` return _lists_ of `Score`s (one for each demographic of interest), so if we want to just score one demographic, we'd have to index into the list in order to call `.function()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7408521-644d-4846-8c2f-c96be4168737",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_tallies([\"BVAP20\"])[0].apply(partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b373e056-5c88-492a-ab62-b6763e412e3e",
   "metadata": {},
   "source": [
    "Moreover, you can only use these scores on demographic columns that have already been tracked as `Tally` updaters when we instantiated our partition. If you try a new column (say, `WVAP20`) things won't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52cd7d-e586-42ce-8328-af8543be1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_tallies([\"WVAP20\"])[0].apply(partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29a6d7-8093-4168-9f6e-8764db044863",
   "metadata": {},
   "source": [
    "Our last demographic updater is `gingles_districts()`, which takes in a dictionary of the same type as `demographic_tallies()` as well as a `threshold` between 0 and 1. Just like the other two demographic scores it returns a list of `Score`s, but here the `Score`s represent the number of districts where the demographic group's share is above the `threshold`. (When the threshold is 0.5 — the default — these districts are called _Gingles' Districts_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2be2d-c295-4b2f-afd2-61d3257bbe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gingles_scores = gingles_districts({\"VAP20\": [\"BVAP20\", \"HVAP20\"]}, threshold=0.5)\n",
    "gingles_dictionary = summarize(partition, gingles_scores)\n",
    "gingles_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae20803-3a54-4a55-9826-151748bf6430",
   "metadata": {},
   "source": [
    "### compactness scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760d8ac-4ccf-42ae-8591-6524fcc9b971",
   "metadata": {},
   "source": [
    "We can count the number of county _splits_ (the number of counties that are assigned to more than one district) as well the number of county _pieces_ (the sum of the number of unique $($_county_, _district_$)$ pairs over every split county).\n",
    "\n",
    "By passing a column name to the `pop_col` keyword argument, you can specify whether you just want splits and pieces that impact population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43c6e2-e14c-49bd-af69-ee30ff5127b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we had a column in our data defining municipal boundaries, we could\n",
    "# similarly county municipal splits/pieces\n",
    "county_scores = [\n",
    "    splits(\"COUNTYFP20\"),\n",
    "    pieces(\"COUNTYFP20\"),\n",
    "]\n",
    "county_dictionary = summarize(partition, county_scores)\n",
    "county_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31cc35f-987e-4030-8c69-66620eba49e7",
   "metadata": {},
   "source": [
    "##  compactness scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdb3d2c-afa2-48d3-b34e-2fc1d026b276",
   "metadata": {},
   "source": [
    "We can also score for compactness in a variety of different ways. \n",
    "\n",
    "The functions `reock`, `polsby_popper`, `schwartzberg`, `convex_hull`, and `pop_poplygon`, get each of these scores for each district in a plan. Unlike the other scoring functions, each of these takes a GeoDataFrame and a crs as arguments. Most of these require the use of a pre-dissolved GeoDataFrame by plan district. This is so the geometries can be used for calculations. \n",
    "\n",
    "Below, we go through the call to each of these functions, which all take similar arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a6ad3f-9c70-483f-bb4c-10034697488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_example = pd.read_csv(\"data/MD_CD_example.csv\", header=None).rename(columns={0:\"GEOID20\", 1: \"assignment\"})\n",
    "vtd_gdf = gpd.read_file(\"data/MD_vtd20\")\n",
    "dissolved_gdf = gpd.GeoDataFrame(md_example.merge(vtd_gdf, on = \"GEOID20\"), geometry=\"geometry\").dissolve(by=\"assignment\", aggfunc=\"sum\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920178e-9c40-4372-8043-deb31a2d2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compactness_scores = [reock(dissolved_gdf, dissolved_gdf.crs),\n",
    "                      polsby_popper(dissolved_gdf, dissolved_gdf.crs), \n",
    "                      schwartzberg(dissolved_gdf, dissolved_gdf.crs),\n",
    "                      convex_hull(dissolved_gdf, dissolved_gdf.crs, assignment_col=\"assignment\"), \n",
    "                      pop_polygon_dict = pop_polygon(vtd_gdf, dissolved_gdf, dissolved_gdf.crs, pop_col=\"TOTPOP20\", assignment_col=\"assignment\")]\n",
    "compactness_dictionary = summarize(compactness_scores, partition)\n",
    "compactness_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea9f7e-a3fe-43a7-a7fa-61cc8134a2e9",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f57be8-86bb-4b57-aa11-96928e70ecbe",
   "metadata": {},
   "source": [
    "We can string together all of our score lists and use them to fully summarize our partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d64d3d-c391-4358-83cd-62f6a6e35532",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = partisan_scores + tally_scores + share_scores + gingles_scores + county_scores + compactness_scores\n",
    "summary_dictionary = summarize(partition, all_scores)\n",
    "summary_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b2674-fd46-4dd8-bd37-074d2f3f6ea3",
   "metadata": {},
   "source": [
    "## misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a880e5-6541-4b16-9555-fe70fc5ec4ea",
   "metadata": {},
   "source": [
    "Other miscellaneous scores we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca725d3-ce74-4875-9698-f1a1a1c0af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_deviation() gives us the maximum deviation from ideal district population, either as a count or as a percent\n",
    "max_deviation(\"TOTPOP20\").apply(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7615d-e425-4674-adc7-cb7c8f5cddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deviation(\"TOTPOP20\", pct=True).apply(partition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coi] *",
   "language": "python",
   "name": "conda-env-coi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
